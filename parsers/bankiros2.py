import requests
from bs4 import BeautifulSoup
import json
import time
import random
import os

save_file = "bankiros_reviews2.json"

# –ó–∞–≥—Ä—É–∂–∞–µ–º —É–∂–µ —Å–æ–±—Ä–∞–Ω–Ω—ã–µ –æ—Ç–∑—ã–≤—ã
if os.path.exists(save_file):
    with open(save_file, "r", encoding="utf-8") as f:
        all_reviews = json.load(f)
    print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(all_reviews)} –æ—Ç–∑—ã–≤–æ–≤ –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Ñ–∞–π–ª–∞.")
else:
    all_reviews = []
    with open(save_file, "w", encoding="utf-8") as f:
        json.dump(all_reviews, f, ensure_ascii=False, indent=4)

# –°—Ç–∞—Ä—Ç–æ–≤–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ (–º–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –≤—Ä—É—á–Ω—É—é)
start_page = len(all_reviews) // 10 + 1
page = start_page
has_next = True

user_agents = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)",
    "Mozilla/5.0 (X11; Linux x86_64)"
]

def get_full_review(full_url):
    """–ü–æ–ª—É—á–∞–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –æ—Ç–∑—ã–≤–∞ –ø–æ —Å—Å—ã–ª–∫–µ"""
    try:
        headers = {"User-Agent": random.choice(user_agents)}
        resp = requests.get(full_url, headers=headers, timeout=15)
        resp.raise_for_status()
        soup = BeautifulSoup(resp.text, "html.parser")
        content_div = soup.find("div", class_="xxx-review__content")
        if content_div:
            return content_div.get_text(separator=" ", strip=True)
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –ø–æ–ª–Ω–æ–≥–æ –æ—Ç–∑—ã–≤–∞ {full_url}: {e}")
    return None

while has_next:
    print(f"üìÑ –ü–∞—Ä—Å–∏–º —Å–ø–∏—Å–æ–∫, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page}...")
    try:
        headers = {"User-Agent": random.choice(user_agents)}
        url = f"https://bankiros.ru/review/show-more?bank_id=131&limit=10&sort=-date&page={page}"
        response = requests.get(url, headers=headers, timeout=20)
        response.raise_for_status()
        data = response.json()

        has_next = data.get("issetNext", False)
        soup = BeautifulSoup(data["reviews"], "html.parser")
        review_cards = soup.find_all("div", class_="xxx-reviews-card__body")

        for card in review_cards:
            # —Ä–µ–π—Ç–∏–Ω–≥
            rating_span = card.find("div", class_="xxx-reviews-rating")
            rating_text = rating_span.find("span").text.strip() if rating_span else "0 –∏–∑ 5"
            rating = int(rating_text.split()[0])

            # —Ç–µ–∫—Å—Ç
            content = card.find("p", class_="xxx-reviews-card__content")
            review_text = content.get_text(separator=" ", strip=True) if content else ""

            # –°–º–æ—Ç—Ä–∏–º, –µ—Å—Ç—å –ª–∏ "–ß–∏—Ç–∞—Ç—å –¥–∞–ª–µ–µ"
            full_link_tag = content.find("a", href=True) if content else None
            if full_link_tag and "otzyv" in full_link_tag["href"]:
                full_url = full_link_tag["href"]
                if full_url.startswith("/"):
                    full_url = "https://bankiros.ru" + full_url
                full_text = get_full_review(full_url)
                if full_text:
                    review_text = full_text
                time.sleep(random.uniform(2, 5))  # –ø–∞—É–∑–∞ –ø–æ—Å–ª–µ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª–Ω–æ–≥–æ –æ—Ç–∑—ã–≤–∞

            all_reviews.append({
                "rating": rating,
                "review": review_text
            })

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        with open(save_file, "w", encoding="utf-8") as f:
            json.dump(all_reviews, f, ensure_ascii=False, indent=4)

        print(f"‚úÖ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page} –≥–æ—Ç–æ–≤–∞. –ù–∞–π–¥–µ–Ω–æ {len(review_cards)} –æ—Ç–∑—ã–≤–æ–≤. –í—Å–µ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {len(all_reviews)}")

        page += 1
        time.sleep(random.uniform(5, 10))  # –ø–∞—É–∑–∞ –º–µ–∂–¥—É —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∏

    except requests.exceptions.HTTPError as e:
        if response.status_code == 429:
            wait = random.uniform(30, 60)
            print(f"–°–∞–π—Ç –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–ª –∑–∞–ø—Ä–æ—Å (429). –ñ–¥—ë–º {int(wait)} —Å–µ–∫—É–Ω–¥...")
            time.sleep(wait)
        else:
            print(f"HTTP –æ—à–∏–±–∫–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page}: {e}. –ñ–¥—ë–º 10 —Å–µ–∫—É–Ω–¥...")
            time.sleep(10)
    except requests.exceptions.RequestException as e:
        print(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page}: {e}. –ñ–¥—ë–º 10 —Å–µ–∫—É–Ω–¥...")
        time.sleep(10)

print(f"–ì–æ—Ç–æ–≤–æ! –í—Å–µ–≥–æ –æ—Ç–∑—ã–≤–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {len(all_reviews)}")
